# FP32/FP16/BF16

一个浮点数使用 $n$ 位来存储一个数值。这些位进一步分为三个不同的组成部分：

- 符号位(Sign)：符号位表示数的正负性。它使用一位，其中 0 表示正数，1 表示负数。
- 指数(Exponent)：指数是一段位，表示底数（通常是二进制表示中的 2）的幂次。指数也可以是正数或负数，允许数表示非常大或非常小的值。
- 尾数/有效数字(Significand/Mantissa)：剩余的位用于存储尾数，也称为有效数字。它代表了数字的有效位数。数字的精度在很大程度上取决于尾数的长度。

这种设计使得浮点数能够覆盖一定范围的值，并具有不同级别的精度。用于此表示的公式为：

$(-1)^{sign} \times base^{exponent} \times {significand} $

为了更好地理解，让我们深入了解一些在深度学习中常用的数据类型：float32（FP32）、float16（FP16）和 bfloat16（BF16）：

![](./assets/bfloat16-format.png)

- FP32 使用 32 位来表示一个数：一位用于表示符号，8 位用于表示指数，剩下的 23 位用于表示尾数。虽然它提供了很高的精度，但 FP32 的缺点是计算和内存占用较高。
- FP16 使用 16 位来存储一个数：一位用于表示符号，5 位用于表示指数，10 位用于表示尾数。虽然这使得它更节省内存并加快计算速度，但由于范围和精度的减少，可能会引入数值不稳定性，可能影响模型的准确性。
- BF16 也是一种 16 位的格式，其中有一位用于表示符号，8 位用于表示指数，7 位用于表示尾数。与 FP16 相比，BF16 扩展了可表示的范围，从而降低了下溢和上溢的风险。尽管由于较少的尾数位数而减少了精度，但 BF16 通常不会对模型性能产生显著影响，并且对于深度学习任务来说是一个有用的折衷方案。

FP32 通常被称为 `full precision`（4 字节），而 BF16 和 FP16 被称为 `half-precision`（2 字节）。

![](./assets/fp32_fp16_bf16_example.png)

# FP32

在线转换器[IEEE-754 Floating Point Converter](https://www.h-schmidt.net/FloatConverter/IEEE754.html)

![](./assets/ieee754_fp32.JPG)

- Sign(符号位): 1 位，0表示整数；1 表示负数
- Exponent(指数位)：8 位，表示整数部分，偏置值是 127
- Fraction(尾数位)：23 位，表示小数部分，也是隐含了首位的1，实际的尾数精度为 24 位

![](./assets/wiki_fp32_jisuan.JPG)

示例：

![](./assets/wiki_fp32_example1.JPG)

计算

![](./assets/wiki_fp32_example2.JPG)

![](./assets/wiki_fp32_example3.JPG)
# FP16

在线转换器[IEEE 754 Calculator](http://weitz.de/ieee/)


![](./assets/1920px-IEEE_754r_Half_Floating_Point_Format.svg.png)

- Sign(符号位): 1 位，0表示整数；1表示负数。
- Exponent(指数位)：5 位，范围为 00001(1) 到 11110(30)，偏置值是 $15$。这个偏置值确保了指数位可以表示从 $-14$ 到 $+15$ 的范围，而不是 1 到 30，注：当指数位都为 00000 和 11111 时，它表示的是一种特殊情况，在 IEEE 754 标准中叫做非规范化情况。
- Fraction(尾数位)：10 位，存储的尾数位数为 10 位，但其隐含了一个前导位，其值为 1，除非指数字段存储了全零。因此，在内存格式中，只有 10 位尾数出现，但总精度为 11 位。在 IEEE 754 术语中，尾数有 10 位，但尾数精度有 11 位（ $ log_{10}2^{11} \approx 3.311 $ 十进制位数，或者 4 个数字 $\pm$ 略小于最后一位的 5 个单位）。

这里的隐含位可能有点难以理解，简单通俗来说，假设尾数部分为 1001000000，为默认在其前面加一个 1，最后变成 1.1001000000 然后换成 10 进制就是 :
```
# 第一种计算方式
1.1001000000 = 1 * 2^0 + 1 * 2^(-1) + 0 * 2^(-2) + 0 * 2^(-3) + 1 * 2^(-4) + 0 * 2^(-5) + 0 * 2^(-6) + 0 * 2^(-7) + 0 * 2^(-8) + 0 * 2^(-9) = 1.5625
# 第二种计算方式
1.1001000000 = 1 + 576(1001000000变成10进制)/1024 = 1.5625
```

FP16 计算的公式如下：

![](./assets/wiki_fp16_jisuan.JPG)

其中第一行表示的是特殊情况，当指数位为全 0 时，尾数位的前导位为 0。

这里还有两个概念 normal number(规格数) & subnormal number(非规格数)，参考文后。subnormal number 表示隐藏前导位为 0。

按照上面的计算公式，可以计算如下示例：

![](./assets/wiki_fp16_examples.JPG)

# BF16
![](./assets/bf16.JPG)

- Sign(符号位): 1 位，0 表示整数；1 表示负数
- Exponent(指数位)：8 位，表示整数部分，偏置值是 127
- Fraction(尾数位)：7 位，表示小数部分，也是隐含了首位的1，实际的尾数精度为 8 位

![](./assets/wiki_bf16_jisuan.JPG)

示例：

bfloat16 精度下的最大有限正值：
$ 7F7F = 0 11111110 1111111 = (2^8 − 1) × 2^{−7} × 2^{127}  \approx 3.38953139 × 10^{38} $

bfloat16 精度和单精度浮点数下的最小规范化正值：
$ 0080 = 0 00000001 0000000 = 2^{−126} \approx 1.175494351 × 10^{−38} $


#  normal number(规格数) & subnormal number(非规格数)

根据 IEEE754 的规定，按照尾数位隐藏的整数部分是 1. 还是 0. 可以将浮点数划分为两类： normal number(规格数) 和 subnormal number(非规格数)

下面以 32 位浮点数为例来解释这些概念。

### normal number(规格数)

就是尾数位隐藏的整数部分是 1. 的数，这种数叫做 normal number，可以理解为"正常的数"。 一般来说，我们遇到的都是 normal number

举例:
20.5 在内存中表示为: 0 1000 0011 **0100 1000 0000 0000 000**

其中尾数部分(即上面的加粗部分)，去掉后面补的零之后为: 01001

但事实上，真实的尾数部分应该是: 1.01001，即前面省略了整数部分 1.

### subnormal number(非规格数)

尾数位隐藏的整数部分为 0. 的数，叫做 subnormal number，也叫作 denormal number，可以理解为"低于正常数的数"

引入 subnormal number 这个概念，是为了在浮点数下溢时，可以逐位的损失精度，以尽可能精确的表达 0 附近的极小数。

为了表示 subnormal number，IEEE754 规定：如果将指数位全部填充为 0，则表示这个数是个 subnormal number

举例: 以 32 位浮点数为例，当你看到类似于 * 00000000 *********************** 这样内存状态的数时，(即指数位全部为0 的数)，就应该知道，这是个 subnormal number，此时这个数的尾数位隐藏的整数不是 1. 而是 0.

# 参考
- https://cloud.google.com/tpu/docs/bfloat16
- https://en.wikipedia.org/wiki/Half-precision_floating-point_format
- https://zhuanlan.zhihu.com/p/657886517
- https://zhuanlan.zhihu.com/p/343037540
- https://en.wikipedia.org/wiki/Single-precision_floating-point_format