# LLM Learning

LLM 学习笔记。

## Pytorch
- [快速开始](./pytorch/quickstart)
- [TorchScript 介绍](./pytorch/torchscript)
- [PyTorch Distributed/DDP/FSDP](./pytorch/distributed)
- [自动微分 (AUTOGRAD)](./pytorch/autograd)

## NLP
- [Perplexity](./nlp/Perplexity.md)

## GPT models
- [Nano GPT](./GPT/nanoGPT)
- [MiniGPT-4](./GPT/miniGPT4/README.md)
- [TinyLlama](./GPT/TinyLlama/README.md)
- [LLAMA](./GPT/Llama)
- [ChatML](./GPT/chatml.md)

## 多模态
- [LLAVA](./Multimodal/LLAVA.md)

## 关键技术
- [FP32/FP16/BF16](./technology/precision/fp32_fp16_bf16.md)
- Tokenizers
- [Flash Attention](./technology/flash_attention/README.md)
- Rotary position embedding
- [KV Cache](./technology/KV_Cache/README.md)
- RMSNorm
- [Quantization 量化](./technology/Quantization/README.md)
- [Decoding Strategies](./technology/decoding_strategies/README.md)

## Training
- [前向和反向传播](./training/backprob/README.md)
- [集合通信](./training/mpi)
- [分布式训练并行化](./training/parallelism/README.md)
- [DeepSpeed](./DeepSpeed)
- [混合精度训练](./training/amp/README.md)
- [优化器](./training/optimizer/)
- [Llama2 微调](./training/finetune/llama2_fine_tune.md)
- Prompt Tuning 和 Prefix Tuning

## Inference
- [vllm](./inference/vllm)
- [TRT-LLM](./inference/TRT-LLM/)
- [MLC-LLM](./inference/MLC-LLM/)
- [推理优化](./inference/optimization)
- [推理框架 Benchmark](./inference/benchmark/README.md)

## Profiling
- [Nsight Systems](./Profiling/nsight_systems.md)
- [Roofline](./Profiling/roofline/README.md)

## RAG (Retrieval Augmented Generation)
- [Embedding](./RAG/Embedding.md)
- [RAG](./RAG/README.md)

## LLM Agents


## 开源项目
- [项目列表](./Opensource/README.md)

## 课程
- [学习课程列表](./Courses/README.md)

## 其他
- [Markdown 数学公式](https://www.cnblogs.com/bytesfly/p/markdown-formula.html)
