# LLM Learning

LLM 学习笔记。

## Pytorch
- [快速开始](./pytorch/quickstart/README.md)
- [TorchScript 介绍](./pytorch/torchscript/README.md)
- [Checkpoint 介绍](./pytorch/checkpoint/README.md)
- [PyTorch Distributed/DDP/FSDP](./pytorch/distributed/README.md)

## NLP
- [Transformer](./nlp/transformer/README.md)
- [Perplexity](./nlp/Perplexity.md)

## GPT models
- [Nano GPT](./GPT/nanoGPT/README.md)
- [MiniGPT-4](./GPT/miniGPT4/README.md)
- [TinyLlama](./GPT/TinyLlama/README.md)
- [LLAMA](./GPT/Llama/README.md)

## 多模态
- [LLAVA](./Multimodal/LLAVA.md)

## 关键技术
- [FP32/FP16/BF16](./technology/precision/fp32_fp16_bf16.md)
- Tokenizers
- [Flash Attention](./technology/flash_attention/README.md)
- Rotary position embedding
- [KV Cache](./technology/KV_Cache/README.md)
- RMSNorm
- [Quantization 量化](./technology/Quantization/README.md)
- [Decoding Strategies](./technology/decoding_strategies/README.md)

## Training
- [MPI](./training/mpi/README.md)
- [DeepSpeed](./DeepSpeed/README.md)
- [混合精度训练](./training/amp/README.md)
- [优化器](./training/optimizer/README.md)
- [Llama2 微调](./training/finetune/llama2_fine_tune.md)
- [Prompt Tuning 和 Prefix Tuning](./)

## Inference
- [llama.cpp](./inference/llama.cpp/README.md)
- [vllm](./inference/vllm/README.md)
- [TRT-LLM](./inference/TRT-LLM/)
- [MLC-LLM](./inference/MLC-LLM/)

## Profiling
- [Nsight Systems](./Profiling/nsight_systems.md)
- [Benchmark](./Profiling/benchmark/README.md)
- [Roofline](./Profiling/roofline/README.md)

## RAG (Retrieval Augmented Generation)
- [Embedding](./RAG/Embedding.md)
- [RAG](./RAG/README.md)

## LLM Agents


## 开源项目
- [项目列表](./Opensource/README.md)

## 课程
- [学习课程列表](./Courses/README.md)

## 其他
- [Markdown 数学公式](https://www.cnblogs.com/bytesfly/p/markdown-formula.html)
