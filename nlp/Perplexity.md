# Perplexity

## Perplexity 是什么

Perplexity，中文翻译为困惑度，是信息论中的一个概念，其可以用来衡量一个随机变量的不确定性，也可以用来衡量模型训练的好坏程度。通常情况下，一个随机变量的 Perplexity 数值越高，代表其不确定性也越高；一个模型推理时的 Perplexity 数值越高，代表模型表现越差，反之亦然。

## 随机变量概率分布的困惑度

对于离散随机变量 $X$​，假设概率分布可以表示为 $p(x)$​​​，那么对应的困惑度为：

$$ 2^{H(p)}=2^{−\sum_{x \in X} p(x)log2p(x)} $$
其中，$H(p)$ 为概率分布 $p$ ​​的熵。可以看到，一个随机变量熵越大，其对应的困惑度也就越大，随机变量的不确定性也就越大。

## 模型分布的困惑度

困惑度也可以用来衡量模型训练的好坏程度，即衡量模型分布和样本分布之间的差异。一般来讲，在模型的训练过程中，模型分布越接近样本分布，模型训练得也就越好。

假设现在有一批数据 $x_1,x_2,x_3,...,x_n$，其对应的经验分布为 $p_r(x)$。现在我们根据这些样本成功训练出了一个模型 $p_θ(x)$
，那么模型分布 $p_θ(x)$ ​​​​的好坏可以由困惑度进行定义： 

$$2^{H(p_r,p_θ)}=2^{−∑_i^n p_r(x_i)log2p_θ(x_i)} $$ 其中，$H(p_r,p_θ)$ ​表示样本的经验分布 $\hat{p_r}$ 和模型分布 $p_θ$ ​之间的交叉熵。假设每个样本 $x_i$ 的生成概率是相等的，即 $p_r(x_i)= \frac{1}{n}$，则模型分布的困惑度可简化为：

$$2^{H(pr,pθ)}=2^{−\frac{1}{n} \sum_i^n log2 p_θ(x_i)}$$

## NLP 领域中的困惑度

在 NLP 领域，语言模型可以用来计算一个句子的概率，假设现在有这样一句话 $s=w_1,w_2,w_3,...,w_n$​​​​​​, 我们可以这样计算这句话的生成概率：

$$p(s)=p(w_1,w_2,...,w_n)=\displaystyle \prod_i^n p(w_i|w_1,w_2,...,w_{i−1})$$
 
在语言模型训练完成之后，如何去评判语言模型的好坏？这时，困惑度就可以发挥作用了。一般来讲，用于评判语言模型的测试集均是合理的、高质量的语料，只要语言模型在测试集上的困惑度越低，则代表语言模型训练地越好，反之亦然。

在了解了语句概率的计算后，则对于语句 $s=w_1,w_2,w_3,...,w_n$​​，其困惑度可以这样来定义：

$$
\begin{align}
perplexity & = p(s)^{-\frac{1}{n}} \\
& = p(w_1,w_2,...,w_n)^{-\frac{1}{n}} \\
& = \sqrt[n]{\frac{1}{p(w_1,w_2,...,w_n)}} \\
& = \sqrt[n]{\prod_i^n \frac{1}{p(w_i|w_1,w_2,...,w_{i−1})}}
\end{align}
$$

显然，测试集中句子的概率越大，困惑度也就越小。



# 参考
- https://medium.com/nlp-tsupei/perplexity%E6%98%AF%E4%BB%80%E9%BA%BC-426f52897513
- https://paddlepedia.readthedocs.io/en/latest/tutorials/deep_learning/metrics/perplexity.html
- https://en.wikipedia.org/wiki/Perplexity